{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1581e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, LogisticRegression\n",
    "from sklearn import svm, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f657925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data and give column names\n",
    "\n",
    "train = pd.read_csv('../../data/feature_selected_train_FD001.csv', sep=',', header=0, engine='python')\n",
    "test = pd.read_csv('../../data/feature_selected_test_FD001.csv', sep=',', header=0, engine='python')\n",
    "y_test = pd.read_csv('../../data/RUL_FD001.csv', sep=',', header=0,  engine='python')\n",
    "\n",
    "index_names = train.columns[[0, 1]]\n",
    "setting_names = train.columns[[2]]\n",
    "sensor_names = train.drop(index_names.union(setting_names), axis = 1).columns # Find something better than union!!\n",
    "scale_columns = sensor_names\n",
    "keep_columns = scale_columns.union(index_names[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ecc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, test, columns):\n",
    "    sc = MinMaxScaler()\n",
    "    scaled_train = train.copy()\n",
    "    scaled_test = test.copy()\n",
    "    scaled_train[columns] = pd.DataFrame(sc.fit_transform(scaled_train[columns]))\n",
    "    scaled_test[columns] = pd.DataFrame(sc.transform(scaled_test[columns]))\n",
    "    return scaled_train, scaled_test\n",
    "\n",
    "def add_remaining_useful_life(df):\n",
    "    grouped_by_unit = df.groupby(by=\"unit_no\")\n",
    "    max_cycle = grouped_by_unit[\"time_cycles\"].max()\n",
    "    \n",
    "    result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_no', right_index=True)\n",
    "    remaining_useful_life = result_frame[\"max_cycle\"] - result_frame[\"time_cycles\"]\n",
    "    result_frame[\"RUL\"] = remaining_useful_life\n",
    "    \n",
    "    result_frame = result_frame.drop(\"max_cycle\", axis=1)\n",
    "    return result_frame\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(history.history['loss'])+1), history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(history.history['val_loss'])+1), history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
    "    \n",
    "def plot_predictions(y_true, y_predicted):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(y_true, label='true')\n",
    "    plt.plot(y_predicted, label='predicted')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf14d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = add_remaining_useful_life(train)\n",
    "y_train = x_train.pop('RUL')\n",
    "x_test = test.groupby(by=\"unit_no\").last().reset_index()\n",
    "x_train_scaled, x_test_scaled = scale_data(x_train, x_test, scale_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f64ec262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "train set RMSE:39.59310521746384, R2:0.669583736222076\n",
      "test set RMSE:36.384392626609255, R2:0.23339664627412604\n",
      "SVM\n",
      "train set RMSE:50.787367009553414, R2:0.4563321092027983\n",
      "test set RMSE:39.36089429878341, R2:0.10283903312676279\n",
      "Decision Tree\n",
      "train set RMSE:0.0, R2:1.0\n",
      "test set RMSE:45.49175749517708, R2:-0.19841127552422044\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "          ('Linear Regression', LinearRegression()), \n",
    "          ('Logistic Regression', LogisticRegression()), \n",
    "          ('SVM', svm.SVC()),\n",
    "          ('Decision Tree', tree.DecisionTreeRegressor())\n",
    "         ]\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    clf = model.fit(x_train_scaled, y_train)\n",
    "    y_hat_train = clf.predict(x_train_scaled)\n",
    "    print(name)\n",
    "    evaluate(y_train, y_hat_train, 'train')\n",
    "    \n",
    "    y_hat_test = clf.predict(x_test_scaled)\n",
    "    evaluate(y_test, y_hat_test)\n",
    "    \n",
    "    #results.append(cv_results)\n",
    "    #names.append(name)\n",
    "    \n",
    "    #this_df = pd.DataFrame(cv_results)\n",
    "    #this_df['model'] = name\n",
    "    #dfs.append(this_df)\n",
    "#final = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0818016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
