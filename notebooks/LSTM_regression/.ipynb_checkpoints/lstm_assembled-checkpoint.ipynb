{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41aede27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Masking\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from support_functions import *\n",
    "from batch_generators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3be0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data and give column names\n",
    "\n",
    "train = pd.read_csv('../../data/feature_selected_train_FD001.csv', sep=',', header=0, engine='python')\n",
    "test = pd.read_csv('../../data/feature_selected_test_FD001.csv', sep=',', header=0, engine='python')\n",
    "y_test = pd.read_csv('../../data/RUL_FD001.csv', sep=',', header=0,  engine='python')\n",
    "\n",
    "index_names = train.columns[[0, 1]]\n",
    "setting_names = train.columns[[2]]\n",
    "sensor_names = train.drop(index_names.union(setting_names), axis = 1).columns # Find something better than union!!\n",
    "scale_columns = sensor_names\n",
    "keep_columns = scale_columns.union(index_names[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27427777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_val, y_val, epochs, model_name):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value = -99., input_shape=(None, x_train.shape[2])))\n",
    "    model.add(LSTM(256, activation='sigmoid', return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    model.compile(loss='mean_squared_error', optimizer = optimizer)\n",
    "    save_best_model = ModelCheckpoint('{}.hdf5'.format(model_name), save_best_only=True, monitor='val_loss', mode='min')\n",
    "    \n",
    "    #model.load_weights('simple_lstm_weights.h5')\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=128,\n",
    "                        callbacks = [save_best_model]\n",
    "                       )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1d17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(x_train, y_train, x_val, y_val, epochs, model_name):\n",
    "    model = load_model('{}.hdf5'.format(model_name))\n",
    "    save_best_model = ModelCheckpoint('{}.hdf5'.format(model_name), save_best_only=True, monitor='val_loss', mode='min')\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=128,\n",
    "                        callbacks = [save_best_model]\n",
    "                       )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd4abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run(train, test, load, sequence_length, epochs, model_name, scale_columns, keep_columns):\n",
    "    x_train = add_remaining_useful_life(train)\n",
    "    x_train_scaled, x_test_scaled = scale_data(x_train, test, scale_columns)\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=1) \n",
    "    x_train, y_train, x_val, y_val = train_val_group_split(x_train_scaled.drop(['RUL'], axis = 1),\n",
    "                                                           x_train_scaled[['RUL', 'unit_no']],\n",
    "                                                           gss, x_train_scaled['unit_no'])\n",
    "    \n",
    "    generator_x_train = generator_training_wrapper(x_train, sequence_length, keep_columns)\n",
    "    generator_x_val = generator_training_wrapper(x_val, sequence_length, keep_columns)\n",
    "\n",
    "    generator_y_train = generator_label_wrapper(y_train, sequence_length, ['RUL'])\n",
    "    generator_y_val = generator_label_wrapper(y_val, sequence_length, ['RUL'])\n",
    "\n",
    "    generator_x_test = generator_test_wrapper(x_test_scaled, sequence_length, keep_columns)\n",
    "    \n",
    "    if(load == True):\n",
    "        model, history = load_models(generator_x_train, generator_y_train, generator_x_val, generator_y_val, epochs, model_name)\n",
    "    else:\n",
    "        model, history = create_model(generator_x_train, generator_y_train, generator_x_val, generator_y_val, epochs, model_name)\n",
    "    \n",
    "    plot_loss(history)\n",
    "    \n",
    "    y_predicted = model.predict(generator_x_train)\n",
    "    evaluate(generator_y_train, y_predicted, 'train')\n",
    "    plot_predictions(generator_y_train, y_predicted)\n",
    "    \n",
    "    y_predicted = model.predict(generator_x_val)\n",
    "    evaluate(generator_y_val, y_predicted, 'val')\n",
    "    plot_predictions(generator_y_val, y_predicted)\n",
    "    \n",
    "    y_predicted = model.predict(generator_x_test)\n",
    "    evaluate(y_test, y_predicted, 'test')\n",
    "    plot_predictions(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdec19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split_engines [  1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  19  20\n",
      "  21  22  23  24  25  26  27  28  29  30  31  35  36  38  39  41  42  43\n",
      "  44  46  47  48  49  50  51  54  55  56  58  59  60  61  62  63  64  65\n",
      "  67  68  69  71  72  73  74  75  76  77  78  80  84  86  87  88  89  90\n",
      "  91  92  95  96  97  98  99 100]\n",
      "validate_split_engines [11 18 32 33 34 37 40 45 52 53 57 66 70 79 81 82 83 85 93 94] \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keep_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-62bdd4466fda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#         scale_columns = scale_columns, keep_columns = keep_columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model_run(train, test, load = False, sequence_length = sequence_length, epochs = epochs, model_name = 'lstm_test',\n\u001b[1;32m----> 6\u001b[1;33m          scale_columns = scale_columns, keep_columns = keep_columns)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-03baf59731d6>\u001b[0m in \u001b[0;36mmodel_run\u001b[1;34m(train, test, load, sequence_length, epochs, model_name, scale_columns, keep_columns)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mgenerator_y_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_label_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'RUL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mgenerator_x_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_test_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\TietoEVRY\\Azure Project\\Azure SDK\\kaggle-phm-internal_project\\notebooks\\LSTM_regression\\batch_generators.py\u001b[0m in \u001b[0;36mgenerator_test_wrapper\u001b[1;34m(df, sequence_length, columns, unit_nos)\u001b[0m\n\u001b[0;32m     36\u001b[0m     test_gen = (list(generator_test_data(df[df['unit_no']==unit_no], sequence_length, keep_columns, -99.))\n\u001b[0;32m     37\u001b[0m            for unit_no in unit_nos)   \n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mcombined_units_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcombined_units_gen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\TietoEVRY\\Azure Project\\Azure SDK\\kaggle-phm-internal_project\\notebooks\\LSTM_regression\\batch_generators.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0munit_nos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unit_no'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     test_gen = (list(generator_test_data(df[df['unit_no']==unit_no], sequence_length, keep_columns, -99.))\n\u001b[1;32m---> 37\u001b[1;33m            for unit_no in unit_nos)   \n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mcombined_units_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcombined_units_gen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keep_columns' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "sequence_length = 100\n",
    "#model_run(train, test, load = True, sequence_length = sequence_length, epochs = epochs, model_name = 'lstm_Azure',\n",
    "#         scale_columns = scale_columns, keep_columns = keep_columns)\n",
    "model_run(train, test, load = False, sequence_length = sequence_length, epochs = epochs, model_name = 'lstm_test',\n",
    "         scale_columns = scale_columns, keep_columns = keep_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c82c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d0b5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
